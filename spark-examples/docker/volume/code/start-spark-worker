#!/bin/bash
set -x
function check_start {
    if [ $1 -ne 0 ]; then
        echo "Failed to start $2: $1"
        exit $1
    fi
}

function check_running {
    ps aux | grep $1 | grep -q -v grep
    status=$?
    if [ $status -ne 0 ]; then
        echo "$1 stopped. Terminating"
        exit $status
    fi
}

function collect_stdout {
    #sed -e '/^$/d' |  jq -R . | sed -e 's/^/{"'"$1"'":/' -e 's/$/}/' | stdbuf -oL fluent-bit -f 10 -v -i stdin -o forward://fluentd:24224
    logger --rfc5424 -n fluentd -P 5140 -t $1
}

hostname=`hostname`
start-hadoop-datanode 2>&1 | collect_stdout datanode &
spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077 2>&1 | collect_stdout spark-worker &
set +o xtrace
while /bin/true; do
    sleep 60000
    check_running start-hadoop-datanode
    check_running org.apache.spark.deploy.worker.Worker
done
