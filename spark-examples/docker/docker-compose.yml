version: '3'
services:
  fluentd:
    read_only: true
    image: fluent/fluentd
    environment:
      FLUENTD_CONF: stdout.conf
    volumes:
      - ./volume/fluentd_conf:/fluentd/etc:ro

  spark-master:
    read_only: true
    build: .
    links:
      - fluentd
    image: local/spark-2
    hostname: namenode
    command: start-spark-master
    environment:
      MASTER: spark://spark-master:7077
    ports:
      - 4040:4040
      - 6066:6066
      - 8080:8080
      - 18080:18080
    volumes:
      - "$HDFS_VOL1"
      - "$HDFS_VOL2"
      - ./volume/spark_input:/mnt/volume:ro

  secondarynamenode:
    read_only: true
    image: local/hadoop-2
    build: .
    links:
      - spark-master:namenode
      - fluentd
    command: start-hadoop-secondarynamenode
    volumes:
      - "$HDFS_VOL1"

  spark-worker:
    read_only: true
    deploy:
      replicas: 2
    image: local/spark-2
    command: start-spark-worker
    links:
      - fluentd
      - spark-master:namenode
      - secondarynamenode
    environment:
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
    volumes:
      - "$HDFS_VOL1"
